from fastapi import FastAPI, Depends, UploadFile, File, HTTPException
from fastapi.middleware.cors import CORSMiddleware
from sqlalchemy.orm import Session
import models, schemas
from database import engine, get_db
import openai, os
from dotenv import load_dotenv
import tempfile
from datetime import date
from auth_routes import router as auth_router
from pathlib import Path

# Load .env
env_path = Path(__file__).parent / '.env'
load_dotenv(dotenv_path=env_path)

# í™˜ê²½ ë³€ìˆ˜ ë¡œë“œ í™•ì¸
print("[ENV] Environment variables loaded:")
print(f"[ENV] KAKAO_CLIENT_ID: {os.getenv('KAKAO_CLIENT_ID')}")
print(f"[ENV] GOOGLE_CLIENT_ID: {os.getenv('GOOGLE_CLIENT_ID')}")
print(f"[ENV] KAKAO_REDIRECT_URI: {os.getenv('KAKAO_REDIRECT_URI')}")
print(f"[ENV] GOOGLE_REDIRECT_URI: {os.getenv('GOOGLE_REDIRECT_URI')}")

openai.api_key = os.getenv("OPENAI_API_KEY")

app = FastAPI()

# CORS ì„¤ì •
origins = [
    "http://localhost:5173",
    "http://127.0.0.1:5173",
]

app.add_middleware(
    CORSMiddleware,
    allow_origins=origins,
    allow_credentials=True,
    allow_methods=["*"],
    allow_headers=["*"],
    expose_headers=["*"],
    max_age=3600,
)

# ë¼ìš°í„° ë“±ë¡
app.include_router(auth_router, prefix="/api/auth")

# DB í…Œì´ë¸” ìƒì„±
models.Base.metadata.create_all(bind=engine)

# í—¬ìŠ¤ ì²´í¬
@app.get("/")
def health_check():
    return {"status": "OK", "service": "LifeBit AI-API"}

USE_GPT = os.getenv("USE_GPT", "False").lower() == "true"

# ìŒì„± ì—…ë¡œë“œ â†’ Whisper + GPT + ê¸°ë¡ ì €ì¥
@app.post("/api/py/voice")
async def process_voice(file: UploadFile = File(...), db: Session = Depends(get_db)):
    try:
        with tempfile.NamedTemporaryFile(delete=False, suffix=".webm") as tmp:
            tmp.write(await file.read())
            temp_path = tmp.name

        print("ğŸ™ï¸ [LOG] Whisper ìš”ì²­ ì‹œì‘")

        with open(temp_path, "rb") as f:
            transcript = openai.Audio.transcribe("whisper-1", f)

        print("ğŸ§ [LOG] Whisper ê²°ê³¼:", transcript["text"])
        user_text = transcript["text"]

        if USE_GPT:
            response = openai.ChatCompletion.create(
                model="gpt-3.5-turbo",
                messages=[
                    {"role": "system", "content": "ìš´ë™ ê¸°ë¡ ë˜ëŠ” ì‹ë‹¨ ê¸°ë¡ì„ ë„ì™€ì£¼ì„¸ìš”. í˜•ì‹ì€ 'ìš´ë™', 'ì‹ë‹¨' ì¤‘ í•˜ë‚˜ë¡œ êµ¬ë¶„ë©ë‹ˆë‹¤."},
                    {"role": "user", "content": user_text}
                ]
            )
            gpt_reply = response.choices[0].message["content"]
            print("ğŸ¤– [LOG] GPT ì‘ë‹µ:", gpt_reply)
        else:
            gpt_reply = "[GPT ë¹„í™œì„±í™” ìƒíƒœì…ë‹ˆë‹¤]"
            print("ğŸ¤– [LOG] GPT í˜¸ì¶œ ìƒëµë¨ (USE_GPT=False)")

        record_type = "exercise" if "ìš´ë™" in gpt_reply else "diet" if "ì‹ë‹¨" in gpt_reply else "exercise"

        if record_type == "exercise":
            new_record = models.ExerciseSession(
                user_id=1,
                exercise_catalog_id=None,
                duration_minutes=30,
                calories_burned=200,
                notes=user_text,
                exercise_date=date.today()
            )
            db.add(new_record)

        elif record_type == "diet":
            new_record = models.MealLog(
                user_id=1,
                food_item_id=None,
                quantity=1.0,
                log_date=date.today()
            )
            db.add(new_record)

        db.commit()
        return {"user_input": user_text, "gpt_reply": gpt_reply}

    except Exception as e:
        print("âŒ [ERROR] ì „ì²´ ì²˜ë¦¬ ì‹¤íŒ¨:", str(e))  # ğŸ’¥ ì´ ë¡œê·¸ ê¼­ í™•ì¸!
        db.rollback()
        raise HTTPException(status_code=500, detail=f"ì„œë²„ ë‚´ë¶€ ì˜¤ë¥˜: {str(e)}")

# ì„œë²„ ì‹¤í–‰
if __name__ == "__main__":
    import uvicorn
    uvicorn.run(app, host="0.0.0.0", port=8001)
