# ğŸ¥ LifeBit ê±´ê°•ë¡œê·¸ í˜ì´ì§€ êµ¬í˜„ ê°€ì´ë“œ

## ğŸ“‹ ëª©ì°¨
1. [ê°œìš” ë° ëª©í‘œ](#ê°œìš”-ë°-ëª©í‘œ)
2. [ê¸°ìˆ  ì•„í‚¤í…ì²˜](#ê¸°ìˆ -ì•„í‚¤í…ì²˜)
3. [ë°ì´í„° íŒŒì´í”„ë¼ì¸ ì„¤ê³„](#ë°ì´í„°-íŒŒì´í”„ë¼ì¸-ì„¤ê³„)
4. [í”„ë¡ íŠ¸ì—”ë“œ êµ¬í˜„ ê³„íš](#í”„ë¡ íŠ¸ì—”ë“œ-êµ¬í˜„-ê³„íš)
5. [ë°±ì—”ë“œ API ì„¤ê³„](#ë°±ì—”ë“œ-api-ì„¤ê³„)
6. [ì‹¤ì‹œê°„ ë°ì´í„° ì²˜ë¦¬](#ì‹¤ì‹œê°„-ë°ì´í„°-ì²˜ë¦¬)
7. [ë¨¸ì‹ ëŸ¬ë‹ ì¶”ì²œ ì‹œìŠ¤í…œ](#ë¨¸ì‹ ëŸ¬ë‹-ì¶”ì²œ-ì‹œìŠ¤í…œ)
8. [Airflow íŒŒì´í”„ë¼ì¸](#airflow-íŒŒì´í”„ë¼ì¸)
9. [êµ¬í˜„ ë‹¨ê³„ë³„ ê³„íš](#êµ¬í˜„-ë‹¨ê³„ë³„-ê³„íš)
10. [í…ŒìŠ¤íŠ¸ ë° ë°°í¬](#í…ŒìŠ¤íŠ¸-ë°-ë°°í¬)

---

## ğŸ¯ ê°œìš” ë° ëª©í‘œ

### í˜ì´ì§€ ëª©ì 
- ì‚¬ìš©ì ê±´ê°• ë°ì´í„°ì˜ **ì‹¤ì‹œê°„ ì‹œê°í™”**
- **ë¨¸ì‹ ëŸ¬ë‹ ê¸°ë°˜ ê°œì¸í™” ì¶”ì²œ** ì œê³µ
- **Airflow íŒŒì´í”„ë¼ì¸**ì„ í†µí•œ ìë™í™”ëœ ë°ì´í„° ì²˜ë¦¬
- ì‚¬ìš©ì ê±´ê°• ëª©í‘œ ë‹¬ì„±ë¥  ì¶”ì 

### í•µì‹¬ ê¸°ëŠ¥
1. **ì‹¤ì‹œê°„ ê±´ê°• ë°ì´í„° ëŒ€ì‹œë³´ë“œ**
2. **AI ê¸°ë°˜ ìš´ë™/ì‹ë‹¨ ì¶”ì²œ**
3. **ìë™í™”ëœ ë°ì´í„° ë¶„ì„ ë° í†µê³„**
4. **ëª©í‘œ ë‹¬ì„±ë¥  ì‹œê°í™”**

---

## ğŸ—ï¸ ê¸°ìˆ  ì•„í‚¤í…ì²˜

### ì „ì²´ ì‹œìŠ¤í…œ êµ¬ì¡°
```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚   Frontend      â”‚    â”‚   Backend       â”‚    â”‚   Database      â”‚
â”‚   (React/Vite)  â”‚â—„â”€â”€â–ºâ”‚   (FastAPI)     â”‚â—„â”€â”€â–ºâ”‚   (Supabase)    â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
         â”‚                       â”‚                       â”‚
         â”‚                       â”‚                       â”‚
         â–¼                       â–¼                       â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚   Real-time     â”‚    â”‚   ML Model      â”‚    â”‚   Airflow       â”‚
â”‚   Updates       â”‚    â”‚   (Scikit-learn)â”‚    â”‚   Pipeline      â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### ê¸°ìˆ  ìŠ¤íƒ ìƒì„¸
```typescript
// í”„ë¡ íŠ¸ì—”ë“œ
- React 18 + TypeScript
- Vite (ë¹Œë“œ ë„êµ¬)
- Tailwind CSS (ìŠ¤íƒ€ì¼ë§)
- Recharts (ì°¨íŠ¸ ë¼ì´ë¸ŒëŸ¬ë¦¬)
- React Query (ë°ì´í„° í˜ì¹­)
- Zustand (ìƒíƒœ ê´€ë¦¬)

// ë°±ì—”ë“œ
- FastAPI (API ì„œë²„)
- SQLAlchemy (ORM)
- Pydantic (ë°ì´í„° ê²€ì¦)
- PyJWT (ì¸ì¦)

// ë°ì´í„°ë² ì´ìŠ¤
- Supabase (PostgreSQL + ì‹¤ì‹œê°„ ê¸°ëŠ¥)
- Redis (ìºì‹±)

// ë¨¸ì‹ ëŸ¬ë‹
- Scikit-learn (ì¶”ì²œ ëª¨ë¸)
- Pandas (ë°ì´í„° ì²˜ë¦¬)
- NumPy (ìˆ˜ì¹˜ ê³„ì‚°)

// ë°ì´í„° íŒŒì´í”„ë¼ì¸
- Apache Airflow (ì›Œí¬í”Œë¡œìš° ìë™í™”)
- Python (ë°ì´í„° ì²˜ë¦¬ ìŠ¤í¬ë¦½íŠ¸)
```

---

## ğŸ”„ ë°ì´í„° íŒŒì´í”„ë¼ì¸ ì„¤ê³„

### ì‹¤ì‹œê°„ ë°ì´í„° í”Œë¡œìš°
```mermaid
graph TD
    A[ì‚¬ìš©ì ë°ì´í„° ì…ë ¥] --> B[Supabase ì‹¤ì‹œê°„ ì €ì¥]
    B --> C[Airflow íŠ¸ë¦¬ê±°]
    C --> D[ë°ì´í„° ì „ì²˜ë¦¬]
    D --> E[ML ëª¨ë¸ ì—…ë°ì´íŠ¸]
    E --> F[ì¶”ì²œ ê²°ê³¼ ìƒì„±]
    F --> G[Redis ìºì‹œ ì €ì¥]
    G --> H[í”„ë¡ íŠ¸ì—”ë“œ ì‹¤ì‹œê°„ ë°˜ì˜]
```

### ë°ì´í„° ì²˜ë¦¬ ë‹¨ê³„
```python
# 1. ë°ì´í„° ìˆ˜ì§‘
user_input â†’ Supabase â†’ ì‹¤ì‹œê°„ ì €ì¥

# 2. ë°ì´í„° ì „ì²˜ë¦¬ (Airflow)
raw_data â†’ ì •ì œ â†’ ì •ê·œí™” â†’ íŠ¹ì„± ì¶”ì¶œ

# 3. ML ëª¨ë¸ í•™ìŠµ
processed_data â†’ ëª¨ë¸ í•™ìŠµ â†’ ì„±ëŠ¥ í‰ê°€ â†’ ëª¨ë¸ ì €ì¥

# 4. ì¶”ì²œ ìƒì„±
user_profile + ëª¨ë¸ â†’ ì¶”ì²œ ê²°ê³¼ â†’ ìºì‹œ ì €ì¥

# 5. ì‹¤ì‹œê°„ ì „ë‹¬
ìºì‹œ â†’ WebSocket â†’ í”„ë¡ íŠ¸ì—”ë“œ
```

---

## ğŸ¨ í”„ë¡ íŠ¸ì—”ë“œ êµ¬í˜„ ê³„íš

### 1. API í†µí•© ê´€ë¦¬ (api.tsx)
```typescript
// apps/frontend-vite/src/api/healthApi.tsx
import { useQuery, useMutation, useQueryClient } from '@tanstack/react-query';
import { supabase } from '../lib/supabase';

// API ì—”ë“œí¬ì¸íŠ¸ íƒ€ì… ì •ì˜
interface HealthApiEndpoints {
  // ê±´ê°• ê¸°ë¡ ê´€ë ¨
  getHealthRecords: (userId: string, period: string) => Promise<HealthRecord[]>;
  createHealthRecord: (data: CreateHealthRecordData) => Promise<HealthRecord>;
  
  // ëª©í‘œ ê´€ë ¨
  getUserGoals: (userId: string) => Promise<UserGoal>;
  updateUserGoals: (userId: string, data: UpdateGoalData) => Promise<UserGoal>;
  
  // ìš´ë™ ê¸°ë¡ ê´€ë ¨
  getExerciseSessions: (userId: string, period: string) => Promise<ExerciseSession[]>;
  createExerciseSession: (data: CreateExerciseData) => Promise<ExerciseSession>;
  
  // ì‹ë‹¨ ê¸°ë¡ ê´€ë ¨
  getMealLogs: (userId: string, period: string) => Promise<MealLog[]>;
  createMealLog: (data: CreateMealData) => Promise<MealLog>;
  
  // í†µê³„ ê´€ë ¨
  getHealthStatistics: (userId: string, period: string) => Promise<HealthStatistics>;
  
  // ì¶”ì²œ ê´€ë ¨
  getRecommendations: (userId: string) => Promise<Recommendation[]>;
  submitFeedback: (recommendationId: string, feedback: FeedbackData) => Promise<void>;
  
  // ì‹¤ì‹œê°„ êµ¬ë…
  subscribeToHealthUpdates: (userId: string, callback: (data: any) => void) => void;
}

// React Query í›…ë“¤
export const useHealthRecords = (userId: string, period: string) => {
  return useQuery({
    queryKey: ['healthRecords', userId, period],
    queryFn: () => healthApi.getHealthRecords(userId, period),
    staleTime: 5 * 60 * 1000, // 5ë¶„
  });
};

export const useUserGoals = (userId: string) => {
  return useQuery({
    queryKey: ['userGoals', userId],
    queryFn: () => healthApi.getUserGoals(userId),
    staleTime: 10 * 60 * 1000, // 10ë¶„
  });
};

export const useRecommendations = (userId: string) => {
  return useQuery({
    queryKey: ['recommendations', userId],
    queryFn: () => healthApi.getRecommendations(userId),
    staleTime: 30 * 60 * 1000, // 30ë¶„
  });
};

// ì‹¤ì‹œê°„ êµ¬ë… í›…
export const useHealthRealtime = (userId: string) => {
  const queryClient = useQueryClient();
  
  useEffect(() => {
    const subscription = healthApi.subscribeToHealthUpdates(userId, (data) => {
      // ì‹¤ì‹œê°„ ë°ì´í„° ì—…ë°ì´íŠ¸ ì‹œ ì¿¼ë¦¬ ë¬´íš¨í™”
      queryClient.invalidateQueries(['healthRecords', userId]);
      queryClient.invalidateQueries(['userGoals', userId]);
      queryClient.invalidateQueries(['recommendations', userId]);
    });
    
    return () => subscription.unsubscribe();
  }, [userId, queryClient]);
};
```

### 2. í˜ì´ì§€ ì»´í¬ë„ŒíŠ¸ êµ¬ì¡°
```typescript
// apps/frontend-vite/src/pages/HealthLog.tsx
import React from 'react';
import { HealthDashboard } from '../components/health/HealthDashboard';
import { RecommendationPanel } from '../components/health/RecommendationPanel';
import { StatisticsCharts } from '../components/health/StatisticsCharts';
import { GoalProgress } from '../components/health/GoalProgress';

const HealthLog: React.FC = () => {
  const { user } = useAuth(); // ì¸ì¦ í›…
  
  return (
    <div className="min-h-screen bg-gray-50">
      <div className="container mx-auto px-4 py-8">
        {/* í—¤ë” */}
        <div className="mb-8">
          <h1 className="text-3xl font-bold text-gray-900">ê±´ê°• ë¡œê·¸</h1>
          <p className="text-gray-600 mt-2">ì‹¤ì‹œê°„ ê±´ê°• ë°ì´í„°ì™€ AI ì¶”ì²œì„ í™•ì¸í•˜ì„¸ìš”</p>
        </div>
        
        {/* ë©”ì¸ ëŒ€ì‹œë³´ë“œ */}
        <div className="grid grid-cols-1 lg:grid-cols-3 gap-6">
          {/* ì™¼ìª½: í†µê³„ ì°¨íŠ¸ */}
          <div className="lg:col-span-2">
            <StatisticsCharts userId={user.id} />
          </div>
          
          {/* ì˜¤ë¥¸ìª½: ì¶”ì²œ íŒ¨ë„ */}
          <div className="lg:col-span-1">
            <RecommendationPanel userId={user.id} />
          </div>
        </div>
        
        {/* í•˜ë‹¨: ëª©í‘œ ì§„í–‰ë¥  */}
        <div className="mt-8">
          <GoalProgress userId={user.id} />
        </div>
      </div>
    </div>
  );
};

export default HealthLog;
```

### 3. ì°¨íŠ¸ ì»´í¬ë„ŒíŠ¸ë“¤
```typescript
// apps/frontend-vite/src/components/health/StatisticsCharts.tsx
import React from 'react';
import { LineChart, Line, XAxis, YAxis, CartesianGrid, Tooltip, ResponsiveContainer } from 'recharts';
import { useHealthRecords } from '../../api/healthApi';

interface StatisticsChartsProps {
  userId: string;
}

export const StatisticsCharts: React.FC<StatisticsChartsProps> = ({ userId }) => {
  const { data: healthRecords, isLoading } = useHealthRecords(userId, 'month');
  
  if (isLoading) {
    return <div className="animate-pulse">ë¡œë”© ì¤‘...</div>;
  }
  
  return (
    <div className="bg-white rounded-lg shadow-md p-6">
      <h2 className="text-xl font-semibold mb-4">ê±´ê°• ì§€í‘œ ì¶”ì´</h2>
      
      {/* ì²´ì¤‘ ë³€í™” ì°¨íŠ¸ */}
      <div className="mb-6">
        <h3 className="text-lg font-medium mb-3">ì²´ì¤‘ ë³€í™”</h3>
        <ResponsiveContainer width="100%" height={300}>
          <LineChart data={healthRecords}>
            <CartesianGrid strokeDasharray="3 3" />
            <XAxis dataKey="record_date" />
            <YAxis />
            <Tooltip />
            <Line type="monotone" dataKey="weight" stroke="#8884d8" />
          </LineChart>
        </ResponsiveContainer>
      </div>
      
      {/* BMI ë³€í™” ì°¨íŠ¸ */}
      <div>
        <h3 className="text-lg font-medium mb-3">BMI ë³€í™”</h3>
        <ResponsiveContainer width="100%" height={300}>
          <LineChart data={healthRecords}>
            <CartesianGrid strokeDasharray="3 3" />
            <XAxis dataKey="record_date" />
            <YAxis />
            <Tooltip />
            <Line type="monotone" dataKey="bmi" stroke="#82ca9d" />
          </LineChart>
        </ResponsiveContainer>
      </div>
    </div>
  );
};
```

---

## ğŸ”§ ë°±ì—”ë“œ API ì„¤ê³„

### 1. FastAPI ì—”ë“œí¬ì¸íŠ¸ êµ¬ì¡°
```python
# apps/ai-api-fastapi/main.py
from fastapi import FastAPI, Depends, HTTPException
from fastapi.middleware.cors import CORSMiddleware
from sqlalchemy.orm import Session
from typing import List, Optional
import redis
import json

app = FastAPI(title="LifeBit Health API", version="1.0.0")

# CORS ì„¤ì •
app.add_middleware(
    CORSMiddleware,
    allow_origins=["http://localhost:5173"],
    allow_credentials=True,
    allow_methods=["*"],
    allow_headers=["*"],
)

# Redis ì—°ê²° (ìºì‹±ìš©)
redis_client = redis.Redis(host='localhost', port=6379, db=0)

# ê±´ê°• ê¸°ë¡ ê´€ë ¨ ì—”ë“œí¬ì¸íŠ¸
@app.get("/api/health-records/{user_id}")
async def get_health_records(
    user_id: int, 
    period: str = "month",
    db: Session = Depends(get_db)
):
    """ì‚¬ìš©ì ê±´ê°• ê¸°ë¡ ì¡°íšŒ"""
    cache_key = f"health_records:{user_id}:{period}"
    
    # ìºì‹œ í™•ì¸
    cached_data = redis_client.get(cache_key)
    if cached_data:
        return json.loads(cached_data)
    
    # ë°ì´í„°ë² ì´ìŠ¤ ì¡°íšŒ
    records = db.query(HealthRecord).filter(
        HealthRecord.user_id == user_id
    ).order_by(HealthRecord.record_date.desc()).all()
    
    # ìºì‹œ ì €ì¥
    redis_client.setex(cache_key, 300, json.dumps(records))  # 5ë¶„ ìºì‹œ
    
    return records

@app.post("/api/health-records")
async def create_health_record(
    record: CreateHealthRecordRequest,
    db: Session = Depends(get_db)
):
    """ê±´ê°• ê¸°ë¡ ìƒì„±"""
    db_record = HealthRecord(**record.dict())
    db.add(db_record)
    db.commit()
    db.refresh(db_record)
    
    # ì‹¤ì‹œê°„ ì—…ë°ì´íŠ¸ë¥¼ ìœ„í•œ ì´ë²¤íŠ¸ ë°œí–‰
    await publish_health_update(db_record.user_id, "health_record_created")
    
    return db_record

# ì¶”ì²œ ê´€ë ¨ ì—”ë“œí¬ì¸íŠ¸
@app.get("/api/recommendations/{user_id}")
async def get_recommendations(user_id: int):
    """ì‚¬ìš©ì ë§ì¶¤ ì¶”ì²œ ì¡°íšŒ"""
    cache_key = f"recommendations:{user_id}"
    
    # ìºì‹œ í™•ì¸
    cached_data = redis_client.get(cache_key)
    if cached_data:
        return json.loads(cached_data)
    
    # ML ëª¨ë¸ì—ì„œ ì¶”ì²œ ìƒì„±
    recommendations = await generate_recommendations(user_id)
    
    # ìºì‹œ ì €ì¥
    redis_client.setex(cache_key, 1800, json.dumps(recommendations))  # 30ë¶„ ìºì‹œ
    
    return recommendations

# í†µê³„ ê´€ë ¨ ì—”ë“œí¬ì¸íŠ¸
@app.get("/api/health-statistics/{user_id}")
async def get_health_statistics(
    user_id: int, 
    period: str = "month",
    db: Session = Depends(get_db)
):
    """ê±´ê°• í†µê³„ ì¡°íšŒ"""
    cache_key = f"health_stats:{user_id}:{period}"
    
    cached_data = redis_client.get(cache_key)
    if cached_data:
        return json.loads(cached_data)
    
    # í†µê³„ ê³„ì‚°
    stats = await calculate_health_statistics(user_id, period, db)
    
    # ìºì‹œ ì €ì¥
    redis_client.setex(cache_key, 600, json.dumps(stats))  # 10ë¶„ ìºì‹œ
    
    return stats
```

### 2. ë°ì´í„° ëª¨ë¸ ì •ì˜
```python
# apps/ai-api-fastapi/models.py
from sqlalchemy import Column, Integer, String, Float, Date, DateTime, ForeignKey
from sqlalchemy.ext.declarative import declarative_base
from sqlalchemy.orm import relationship
from datetime import datetime
import uuid

Base = declarative_base()

class HealthRecord(Base):
    __tablename__ = "health_records"
    
    health_record_id = Column(Integer, primary_key=True, index=True)
    uuid = Column(String, unique=True, default=lambda: str(uuid.uuid4()))
    user_id = Column(Integer, ForeignKey("users.user_id"))
    weight = Column(Float)
    bmi = Column(Float)
    record_date = Column(Date, nullable=False)
    created_at = Column(DateTime, default=datetime.utcnow)

class UserGoal(Base):
    __tablename__ = "user_goals"
    
    user_goal_id = Column(Integer, primary_key=True, index=True)
    uuid = Column(String, unique=True, default=lambda: str(uuid.uuid4()))
    user_id = Column(Integer, ForeignKey("users.user_id"))
    weekly_workout_target = Column(Integer, default=3)
    daily_carbs_target = Column(Integer, default=200)
    daily_protein_target = Column(Integer, default=120)
    daily_fat_target = Column(Integer, default=60)
    created_at = Column(DateTime, default=datetime.utcnow)
    updated_at = Column(DateTime, default=datetime.utcnow, onupdate=datetime.utcnow)
```

---

## âš¡ ì‹¤ì‹œê°„ ë°ì´í„° ì²˜ë¦¬

### 1. Supabase ì‹¤ì‹œê°„ êµ¬ë…
```typescript
// apps/frontend-vite/src/lib/supabase.ts
import { createClient } from '@supabase/supabase-js';

const supabaseUrl = import.meta.env.VITE_SUPABASE_URL;
const supabaseKey = import.meta.env.VITE_SUPABASE_ANON_KEY;

export const supabase = createClient(supabaseUrl, supabaseKey);

// ì‹¤ì‹œê°„ êµ¬ë… ì„¤ì •
export const subscribeToHealthUpdates = (userId: string, callback: (data: any) => void) => {
  const subscription = supabase
    .channel('health_updates')
    .on(
      'postgres_changes',
      {
        event: '*',
        schema: 'public',
        table: 'health_records',
        filter: `user_id=eq.${userId}`
      },
      (payload) => {
        callback(payload);
      }
    )
    .on(
      'postgres_changes',
      {
        event: '*',
        schema: 'public',
        table: 'user_goals',
        filter: `user_id=eq.${userId}`
      },
      (payload) => {
        callback(payload);
      }
    )
    .subscribe();

  return subscription;
};
```

### 2. WebSocket ì‹¤ì‹œê°„ ì—…ë°ì´íŠ¸
```python
# apps/ai-api-fastapi/websocket.py
from fastapi import WebSocket, WebSocketDisconnect
from typing import Dict
import json

class ConnectionManager:
    def __init__(self):
        self.active_connections: Dict[int, WebSocket] = {}

    async def connect(self, websocket: WebSocket, user_id: int):
        await websocket.accept()
        self.active_connections[user_id] = websocket

    def disconnect(self, user_id: int):
        if user_id in self.active_connections:
            del self.active_connections[user_id]

    async def send_personal_message(self, message: str, user_id: int):
        if user_id in self.active_connections:
            await self.active_connections[user_id].send_text(message)

    async def broadcast(self, message: str):
        for connection in self.active_connections.values():
            await connection.send_text(message)

manager = ConnectionManager()

@app.websocket("/ws/{user_id}")
async def websocket_endpoint(websocket: WebSocket, user_id: int):
    await manager.connect(websocket, user_id)
    try:
        while True:
            data = await websocket.receive_text()
            # ë©”ì‹œì§€ ì²˜ë¦¬
    except WebSocketDisconnect:
        manager.disconnect(user_id)
```

---

## ğŸ¤– ë¨¸ì‹ ëŸ¬ë‹ ì¶”ì²œ ì‹œìŠ¤í…œ

### 1. ì¶”ì²œ ëª¨ë¸ ì„¤ê³„
```python
# apps/ai-api-fastapi/ml/recommendation_model.py
import pandas as pd
import numpy as np
from sklearn.ensemble import RandomForestRegressor
from sklearn.preprocessing import StandardScaler
from sklearn.model_selection import train_test_split
import joblib
import os

class HealthRecommendationModel:
    def __init__(self):
        self.model = RandomForestRegressor(n_estimators=100, random_state=42)
        self.scaler = StandardScaler()
        self.model_path = "models/health_recommendation_model.pkl"
        self.scaler_path = "models/health_scaler.pkl"
        
    def prepare_features(self, user_data: dict) -> np.ndarray:
        """ì‚¬ìš©ì ë°ì´í„°ë¥¼ íŠ¹ì„± ë²¡í„°ë¡œ ë³€í™˜"""
        features = [
            user_data.get('age', 30),
            user_data.get('weight', 70),
            user_data.get('height', 170),
            user_data.get('weekly_workout_target', 3),
            user_data.get('daily_carbs_target', 200),
            user_data.get('daily_protein_target', 120),
            user_data.get('daily_fat_target', 60),
            user_data.get('streak_days', 0),
            user_data.get('total_score', 0)
        ]
        return np.array(features).reshape(1, -1)
    
    def train(self, training_data: pd.DataFrame):
        """ëª¨ë¸ í•™ìŠµ"""
        X = training_data.drop(['target'], axis=1)
        y = training_data['target']
        
        X_train, X_test, y_train, y_test = train_test_split(
            X, y, test_size=0.2, random_state=42
        )
        
        # íŠ¹ì„± ìŠ¤ì¼€ì¼ë§
        X_train_scaled = self.scaler.fit_transform(X_train)
        X_test_scaled = self.scaler.transform(X_test)
        
        # ëª¨ë¸ í•™ìŠµ
        self.model.fit(X_train_scaled, y_train)
        
        # ëª¨ë¸ ì €ì¥
        self.save_model()
        
        return self.model.score(X_test_scaled, y_test)
    
    def predict(self, user_data: dict) -> dict:
        """ì‚¬ìš©ì ë§ì¶¤ ì¶”ì²œ ìƒì„±"""
        features = self.prepare_features(user_data)
        features_scaled = self.scaler.transform(features)
        
        prediction = self.model.predict(features_scaled)[0]
        
        # ì¶”ì²œ ë¡œì§
        recommendations = self.generate_recommendations(user_data, prediction)
        
        return recommendations
    
    def generate_recommendations(self, user_data: dict, prediction: float) -> dict:
        """ì¶”ì²œ ê²°ê³¼ ìƒì„±"""
        recommendations = {
            'exercise_recommendations': [],
            'nutrition_recommendations': [],
            'health_tips': []
        }
        
        # ìš´ë™ ì¶”ì²œ
        if user_data.get('weekly_workout_target', 0) < 3:
            recommendations['exercise_recommendations'].append({
                'type': 'cardio',
                'duration': 30,
                'intensity': 'moderate',
                'reason': 'ì£¼ê°„ ìš´ë™ ëª©í‘œ ë‹¬ì„±ì„ ìœ„í•œ ìœ ì‚°ì†Œ ìš´ë™'
            })
        
        # ì˜ì–‘ ì¶”ì²œ
        if user_data.get('daily_protein_target', 0) < 100:
            recommendations['nutrition_recommendations'].append({
                'type': 'protein',
                'food': 'ë‹­ê°€ìŠ´ì‚´',
                'amount': '150g',
                'reason': 'ë‹¨ë°±ì§ˆ ì„­ì·¨ ëª©í‘œ ë‹¬ì„±ì„ ìœ„í•œ ì¶”ì²œ'
            })
        
        # ê±´ê°• íŒ
        recommendations['health_tips'].append({
            'tip': 'ì¶©ë¶„í•œ ìˆ˜ë©´ì„ ì·¨í•˜ì„¸ìš”',
            'priority': 'high'
        })
        
        return recommendations
    
    def save_model(self):
        """ëª¨ë¸ ì €ì¥"""
        os.makedirs('models', exist_ok=True)
        joblib.dump(self.model, self.model_path)
        joblib.dump(self.scaler, self.scaler_path)
    
    def load_model(self):
        """ëª¨ë¸ ë¡œë“œ"""
        if os.path.exists(self.model_path):
            self.model = joblib.load(self.model_path)
            self.scaler = joblib.load(self.scaler_path)
            return True
        return False
```

### 2. ì¶”ì²œ API ì—”ë“œí¬ì¸íŠ¸
```python
# apps/ai-api-fastapi/main.py
from ml.recommendation_model import HealthRecommendationModel

recommendation_model = HealthRecommendationModel()

@app.get("/api/recommendations/{user_id}")
async def get_recommendations(user_id: int, db: Session = Depends(get_db)):
    """ì‚¬ìš©ì ë§ì¶¤ ì¶”ì²œ ì¡°íšŒ"""
    
    # ì‚¬ìš©ì ë°ì´í„° ì¡°íšŒ
    user = db.query(User).filter(User.user_id == user_id).first()
    user_goals = db.query(UserGoal).filter(UserGoal.user_id == user_id).first()
    user_rankings = db.query(UserRanking).filter(UserRanking.user_id == user_id).first()
    
    if not user:
        raise HTTPException(status_code=404, detail="User not found")
    
    # ì‚¬ìš©ì ë°ì´í„° ì¤€ë¹„
    user_data = {
        'age': user.age,
        'weight': user.weight,
        'height': user.height,
        'weekly_workout_target': user_goals.weekly_workout_target if user_goals else 3,
        'daily_carbs_target': user_goals.daily_carbs_target if user_goals else 200,
        'daily_protein_target': user_goals.daily_protein_target if user_goals else 120,
        'daily_fat_target': user_goals.daily_fat_target if user_goals else 60,
        'streak_days': user_rankings.streak_days if user_rankings else 0,
        'total_score': user_rankings.total_score if user_rankings else 0
    }
    
    # ì¶”ì²œ ìƒì„±
    recommendations = recommendation_model.predict(user_data)
    
    # ì¶”ì²œ ê²°ê³¼ ì €ì¥
    recommendation_record = Recommendation(
        user_id=user_id,
        recommendation_data=recommendations
    )
    db.add(recommendation_record)
    db.commit()
    
    return recommendations
```

---

## ğŸ”„ Airflow íŒŒì´í”„ë¼ì¸

### 1. DAG êµ¬ì¡° ì„¤ê³„
```python
# dags/health_data_pipeline.py
from airflow import DAG
from airflow.operators.python_operator import PythonOperator
from airflow.operators.bash_operator import BashOperator
from datetime import datetime, timedelta
import pandas as pd
import numpy as np
from sqlalchemy import create_engine
import logging

default_args = {
    'owner': 'lifebit',
    'depends_on_past': False,
    'start_date': datetime(2024, 1, 1),
    'email_on_failure': False,
    'email_on_retry': False,
    'retries': 1,
    'retry_delay': timedelta(minutes=5),
}

dag = DAG(
    'health_data_pipeline',
    default_args=default_args,
    description='LifeBit ê±´ê°• ë°ì´í„° ì²˜ë¦¬ íŒŒì´í”„ë¼ì¸',
    schedule_interval='0 */6 * * *',  # 6ì‹œê°„ë§ˆë‹¤ ì‹¤í–‰
    catchup=False
)

def extract_health_data(**context):
    """ê±´ê°• ë°ì´í„° ì¶”ì¶œ"""
    logging.info("ê±´ê°• ë°ì´í„° ì¶”ì¶œ ì‹œì‘")
    
    # Supabaseì—ì„œ ë°ì´í„° ì¶”ì¶œ
    engine = create_engine('postgresql://user:password@localhost/lifebit_db')
    
    # ìµœê·¼ 24ì‹œê°„ ë°ì´í„° ì¶”ì¶œ
    query = """
    SELECT 
        hr.*, ug.weekly_workout_target, ug.daily_carbs_target,
        ug.daily_protein_target, ug.daily_fat_target
    FROM health_records hr
    LEFT JOIN user_goals ug ON hr.user_id = ug.user_id
    WHERE hr.created_at >= NOW() - INTERVAL '24 hours'
    """
    
    df = pd.read_sql(query, engine)
    
    # ë°ì´í„°ë¥¼ XComì— ì €ì¥
    context['task_instance'].xcom_push(key='health_data', value=df.to_dict())
    
    logging.info(f"ì¶”ì¶œëœ ë°ì´í„°: {len(df)} ê±´")
    return len(df)

def transform_health_data(**context):
    """ê±´ê°• ë°ì´í„° ë³€í™˜ ë° ì „ì²˜ë¦¬"""
    logging.info("ê±´ê°• ë°ì´í„° ë³€í™˜ ì‹œì‘")
    
    # XComì—ì„œ ë°ì´í„° ê°€ì ¸ì˜¤ê¸°
    data_dict = context['task_instance'].xcom_pull(task_ids='extract_health_data', key='health_data')
    df = pd.DataFrame(data_dict)
    
    # ë°ì´í„° ì •ì œ
    df = df.dropna(subset=['weight', 'bmi'])
    df['bmi_category'] = pd.cut(df['bmi'], 
                               bins=[0, 18.5, 25, 30, 100], 
                               labels=['ì €ì²´ì¤‘', 'ì •ìƒ', 'ê³¼ì²´ì¤‘', 'ë¹„ë§Œ'])
    
    # íŠ¹ì„± ì—”ì§€ë‹ˆì–´ë§
    df['weight_change'] = df.groupby('user_id')['weight'].diff()
    df['bmi_change'] = df.groupby('user_id')['bmi'].diff()
    
    # ë³€í™˜ëœ ë°ì´í„° ì €ì¥
    context['task_instance'].xcom_push(key='transformed_data', value=df.to_dict())
    
    logging.info(f"ë³€í™˜ëœ ë°ì´í„°: {len(df)} ê±´")
    return len(df)

def train_ml_model(**context):
    """ë¨¸ì‹ ëŸ¬ë‹ ëª¨ë¸ í•™ìŠµ"""
    logging.info("ML ëª¨ë¸ í•™ìŠµ ì‹œì‘")
    
    # ë³€í™˜ëœ ë°ì´í„° ê°€ì ¸ì˜¤ê¸°
    data_dict = context['task_instance'].xcom_pull(task_ids='transform_health_data', key='transformed_data')
    df = pd.DataFrame(data_dict)
    
    if len(df) < 10:
        logging.warning("í•™ìŠµ ë°ì´í„°ê°€ ë¶€ì¡±í•©ë‹ˆë‹¤")
        return 0
    
    # ëª¨ë¸ í•™ìŠµ (ê°„ë‹¨í•œ ì˜ˆì‹œ)
    from sklearn.ensemble import RandomForestRegressor
    from sklearn.model_selection import train_test_split
    
    # íŠ¹ì„± ì„ íƒ
    features = ['weight', 'bmi', 'weekly_workout_target', 'daily_carbs_target']
    X = df[features].dropna()
    y = df.loc[X.index, 'bmi']  # BMI ì˜ˆì¸¡
    
    if len(X) < 5:
        logging.warning("í•™ìŠµ ê°€ëŠ¥í•œ ë°ì´í„°ê°€ ë¶€ì¡±í•©ë‹ˆë‹¤")
        return 0
    
    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)
    
    model = RandomForestRegressor(n_estimators=50, random_state=42)
    model.fit(X_train, y_train)
    
    # ëª¨ë¸ ì„±ëŠ¥ í‰ê°€
    score = model.score(X_test, y_test)
    logging.info(f"ëª¨ë¸ ì„±ëŠ¥ ì ìˆ˜: {score:.3f}")
    
    # ëª¨ë¸ ì €ì¥
    import joblib
    joblib.dump(model, '/tmp/health_model.pkl')
    
    return score

def update_recommendations(**context):
    """ì¶”ì²œ ê²°ê³¼ ì—…ë°ì´íŠ¸"""
    logging.info("ì¶”ì²œ ê²°ê³¼ ì—…ë°ì´íŠ¸ ì‹œì‘")
    
    # ëª¨ë¸ ë¡œë“œ
    import joblib
    model = joblib.load('/tmp/health_model.pkl')
    
    # ì‚¬ìš©ìë³„ ì¶”ì²œ ìƒì„±
    engine = create_engine('postgresql://user:password@localhost/lifebit_db')
    
    # í™œì„± ì‚¬ìš©ì ì¡°íšŒ
    users_query = "SELECT user_id FROM users WHERE created_at >= NOW() - INTERVAL '30 days'"
    users_df = pd.read_sql(users_query, engine)
    
    recommendations = []
    for user_id in users_df['user_id']:
        # ì‚¬ìš©ì ë°ì´í„° ì¡°íšŒ
        user_data_query = f"""
        SELECT 
            u.age, u.weight, u.height,
            ug.weekly_workout_target, ug.daily_carbs_target
        FROM users u
        LEFT JOIN user_goals ug ON u.user_id = ug.user_id
        WHERE u.user_id = {user_id}
        """
        user_data = pd.read_sql(user_data_query, engine)
        
        if not user_data.empty and not user_data.isna().any().any():
            # ì¶”ì²œ ìƒì„±
            features = user_data[['weight', 'height', 'weekly_workout_target', 'daily_carbs_target']].values
            prediction = model.predict(features)[0]
            
            recommendation = {
                'user_id': user_id,
                'recommendation_data': {
                    'predicted_bmi': float(prediction),
                    'exercise_tip': 'ì£¼ 3íšŒ ì´ìƒ ìš´ë™ì„ ê¶Œì¥í•©ë‹ˆë‹¤' if user_data['weekly_workout_target'].iloc[0] < 3 else 'ì¢‹ì€ ìš´ë™ ìŠµê´€ì„ ìœ ì§€í•˜ì„¸ìš”',
                    'nutrition_tip': 'ê· í˜• ì¡íŒ ì‹ë‹¨ì„ ì„­ì·¨í•˜ì„¸ìš”'
                }
            }
            recommendations.append(recommendation)
    
    # ì¶”ì²œ ê²°ê³¼ ì €ì¥
    if recommendations:
        recommendations_df = pd.DataFrame(recommendations)
        recommendations_df.to_sql('recommendation', engine, if_exists='append', index=False)
    
    logging.info(f"ì—…ë°ì´íŠ¸ëœ ì¶”ì²œ: {len(recommendations)} ê±´")
    return len(recommendations)

# íƒœìŠ¤í¬ ì •ì˜
extract_task = PythonOperator(
    task_id='extract_health_data',
    python_callable=extract_health_data,
    dag=dag
)

transform_task = PythonOperator(
    task_id='transform_health_data',
    python_callable=transform_health_data,
    dag=dag
)

train_task = PythonOperator(
    task_id='train_ml_model',
    python_callable=train_ml_model,
    dag=dag
)

update_task = PythonOperator(
    task_id='update_recommendations',
    python_callable=update_recommendations,
    dag=dag
)

# íƒœìŠ¤í¬ ìˆœì„œ ì •ì˜
extract_task >> transform_task >> train_task >> update_task
```

### 2. Airflow ì„¤ì •
```yaml
# docker-compose.ymlì— Airflow ì¶”ê°€
version: '3.8'
services:
  # ê¸°ì¡´ ì„œë¹„ìŠ¤ë“¤...
  
  airflow-webserver:
    image: apache/airflow:2.7.1
    depends_on:
      - postgres-db
    environment:
      - AIRFLOW__CORE__EXECUTOR=LocalExecutor
      - AIRFLOW__CORE__SQL_ALCHEMY_CONN=postgresql+psycopg2://airflow:airflow@postgres-db/airflow
      - AIRFLOW__CORE__LOAD_EXAMPLES=False
    volumes:
      - ./dags:/opt/airflow/dags
      - ./logs:/opt/airflow/logs
      - ./plugins:/opt/airflow/plugins
    ports:
      - "8080:8080"
    command: webserver
    healthcheck:
      test: ["CMD", "curl", "--fail", "http://localhost:8080/health"]
      interval: 30s
      timeout: 10s
      retries: 5

  airflow-scheduler:
    image: apache/airflow:2.7.1
    depends_on:
      - airflow-webserver
    environment:
      - AIRFLOW__CORE__EXECUTOR=LocalExecutor
      - AIRFLOW__CORE__SQL_ALCHEMY_CONN=postgresql+psycopg2://airflow:airflow@postgres-db/airflow
      - AIRFLOW__CORE__LOAD_EXAMPLES=False
    volumes:
      - ./dags:/opt/airflow/dags
      - ./logs:/opt/airflow/logs
      - ./plugins:/opt/airflow/plugins
    command: scheduler
```

---

## ğŸ“‹ êµ¬í˜„ ë‹¨ê³„ë³„ ê³„íš

### 1ë‹¨ê³„: ê¸°ë³¸ ì¸í”„ë¼ êµ¬ì¶• (1-2ì¼)
```bash
# 1. Supabase ì„¤ì •
- í”„ë¡œì íŠ¸ ìƒì„±
- ë°ì´í„°ë² ì´ìŠ¤ ì—°ê²° ì„¤ì •
- ì‹¤ì‹œê°„ ê¸°ëŠ¥ í™œì„±í™”

# 2. Airflow ì„¤ì •
- Docker Composeì— Airflow ì¶”ê°€
- DAG íŒŒì¼ ì‘ì„±
- ìŠ¤ì¼€ì¤„ëŸ¬ ì„¤ì •

# 3. Redis ì„¤ì •
- ìºì‹± ì„œë²„ êµ¬ì¶•
- ì—°ê²° ì„¤ì •
```

### 2ë‹¨ê³„: ë°±ì—”ë“œ API ê°œë°œ (2-3ì¼)
```bash
# 1. FastAPI ì—”ë“œí¬ì¸íŠ¸ êµ¬í˜„
- ê±´ê°• ê¸°ë¡ CRUD
- í†µê³„ ê³„ì‚° API
- ì¶”ì²œ API

# 2. ë°ì´í„°ë² ì´ìŠ¤ ëª¨ë¸ êµ¬í˜„
- SQLAlchemy ëª¨ë¸ ì •ì˜
- ë§ˆì´ê·¸ë ˆì´ì…˜ ìŠ¤í¬ë¦½íŠ¸

# 3. ì‹¤ì‹œê°„ ê¸°ëŠ¥ êµ¬í˜„
- WebSocket ì—°ê²°
- Supabase ì‹¤ì‹œê°„ êµ¬ë…
```

### 3ë‹¨ê³„: ë¨¸ì‹ ëŸ¬ë‹ ëª¨ë¸ ê°œë°œ (2-3ì¼)
```bash
# 1. ë°ì´í„° ì „ì²˜ë¦¬
- íŠ¹ì„± ì—”ì§€ë‹ˆì–´ë§
- ë°ì´í„° ì •ì œ

# 2. ëª¨ë¸ í•™ìŠµ
- ì¶”ì²œ ì•Œê³ ë¦¬ì¦˜ êµ¬í˜„
- ì„±ëŠ¥ í‰ê°€

# 3. ëª¨ë¸ ë°°í¬
- ëª¨ë¸ ì €ì¥/ë¡œë“œ
- API ì—°ë™
```

### 4ë‹¨ê³„: í”„ë¡ íŠ¸ì—”ë“œ ê°œë°œ (3-4ì¼)
```bash
# 1. API í†µí•©
- healthApi.tsx êµ¬í˜„
- React Query ì„¤ì •

# 2. ì°¨íŠ¸ ì»´í¬ë„ŒíŠ¸
- Recharts ì„¤ì •
- ì°¨íŠ¸ ì»´í¬ë„ŒíŠ¸ êµ¬í˜„

# 3. ì‹¤ì‹œê°„ ì—…ë°ì´íŠ¸
- WebSocket ì—°ê²°
- ì‹¤ì‹œê°„ ë°ì´í„° ë°˜ì˜
```

### 5ë‹¨ê³„: í†µí•© ë° í…ŒìŠ¤íŠ¸ (1-2ì¼)
```bash
# 1. ì „ì²´ ì‹œìŠ¤í…œ í†µí•©
- ëª¨ë“  ì»´í¬ë„ŒíŠ¸ ì—°ê²°
- ì—ëŸ¬ ì²˜ë¦¬

# 2. ì„±ëŠ¥ ìµœì í™”
- ìºì‹± ìµœì í™”
- ë¡œë”© ì„±ëŠ¥ ê°œì„ 

# 3. í…ŒìŠ¤íŠ¸
- ë‹¨ìœ„ í…ŒìŠ¤íŠ¸
- í†µí•© í…ŒìŠ¤íŠ¸
```

---

## ğŸ§ª í…ŒìŠ¤íŠ¸ ë° ë°°í¬

### 1. í…ŒìŠ¤íŠ¸ ì „ëµ
```typescript
// ë‹¨ìœ„ í…ŒìŠ¤íŠ¸
- API ì—”ë“œí¬ì¸íŠ¸ í…ŒìŠ¤íŠ¸
- ì»´í¬ë„ŒíŠ¸ í…ŒìŠ¤íŠ¸
- ëª¨ë¸ ì„±ëŠ¥ í…ŒìŠ¤íŠ¸

// í†µí•© í…ŒìŠ¤íŠ¸
- ì „ì²´ ì›Œí¬í”Œë¡œìš° í…ŒìŠ¤íŠ¸
- ì‹¤ì‹œê°„ ë°ì´í„° ë™ê¸°í™” í…ŒìŠ¤íŠ¸

// ì„±ëŠ¥ í…ŒìŠ¤íŠ¸
- ë¡œë”© ì‹œê°„ ì¸¡ì •
- ë©”ëª¨ë¦¬ ì‚¬ìš©ëŸ‰ ëª¨ë‹ˆí„°ë§
```

### 2. ë°°í¬ ì²´í¬ë¦¬ìŠ¤íŠ¸
```bash
# í™˜ê²½ ë³€ìˆ˜ ì„¤ì •
- Supabase ì—°ê²° ì •ë³´
- Redis ì—°ê²° ì •ë³´
- Airflow ì„¤ì •

# ë³´ì•ˆ ì„¤ì •
- API í‚¤ ê´€ë¦¬
- CORS ì„¤ì •
- ì¸ì¦ í† í° ê´€ë¦¬

# ëª¨ë‹ˆí„°ë§ ì„¤ì •
- ë¡œê·¸ ìˆ˜ì§‘
- ì„±ëŠ¥ ëª¨ë‹ˆí„°ë§
- ì—ëŸ¬ ì¶”ì 
```

---

## ğŸ“ ì¶”ê°€ ì°¸ê³ ì‚¬í•­

### ê°œë°œ ì‹œ ì£¼ì˜ì‚¬í•­
1. **ì‹¤ì‹œê°„ ë°ì´í„° ë™ê¸°í™”**: Supabase ì‹¤ì‹œê°„ ê¸°ëŠ¥ê³¼ WebSocketì„ ì ì ˆíˆ ì¡°í•©
2. **ìºì‹± ì „ëµ**: Redisë¥¼ í™œìš©í•œ íš¨ìœ¨ì ì¸ ìºì‹± êµ¬í˜„
3. **ì—ëŸ¬ ì²˜ë¦¬**: ë„¤íŠ¸ì›Œí¬ ì˜¤ë¥˜, ë°ì´í„° ìœ íš¨ì„± ê²€ì¦ ë“± ì² ì €í•œ ì—ëŸ¬ ì²˜ë¦¬
4. **ì„±ëŠ¥ ìµœì í™”**: ëŒ€ìš©ëŸ‰ ë°ì´í„° ì²˜ë¦¬ ì‹œ í˜ì´ì§€ë„¤ì´ì…˜, ê°€ìƒí™” ë“± ê³ ë ¤

### í™•ì¥ ê°€ëŠ¥ì„±
1. **ì¶”ê°€ ì°¨íŠ¸ íƒ€ì…**: íˆíŠ¸ë§µ, ì‚°ì ë„, ë°•ìŠ¤í”Œë¡¯ ë“±
2. **ê³ ê¸‰ ë¶„ì„**: ì‹œê³„ì—´ ë¶„ì„, ì´ìƒì¹˜ íƒì§€ ë“±
3. **ê°œì¸í™”**: ì‚¬ìš©ìë³„ ëŒ€ì‹œë³´ë“œ ì»¤ìŠ¤í„°ë§ˆì´ì§•
4. **ëª¨ë°”ì¼ ìµœì í™”**: ë°˜ì‘í˜• ë””ìì¸ ë° í„°ì¹˜ ì¸í„°ë™ì…˜

**ë§ˆì§€ë§‰ ì—…ë°ì´íŠ¸:** 2024ë…„ 12ì›” 19ì¼  
**ì‘ì„±ì:** ê°œë°œíŒ€  
**ë²„ì „:** 1.0 